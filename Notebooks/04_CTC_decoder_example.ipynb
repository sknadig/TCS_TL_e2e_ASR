{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "import numpy as np\n",
    "from six.moves import zip_longest\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _testCTCDecoder(self, decoder, inputs, seq_lens, log_prob_truth,\n",
    "                      decode_truth, expected_err_re=None, **decoder_args):\n",
    "    inputs_t = [tf.convert_to_tensor(x) for x in inputs]\n",
    "    # convert inputs_t into a [max_time x batch_size x depth] tensor\n",
    "    # from a len time python list of [batch_size x depth] tensors\n",
    "    inputs_t = tf.pack(inputs_t)\n",
    "\n",
    "    with self.test_session(use_gpu=False) as sess:\n",
    "      decoded_list, log_probability = decoder(\n",
    "          inputs_t,\n",
    "          sequence_length=seq_lens, **decoder_args)\n",
    "      decoded_unwrapped = list(flatten([\n",
    "          (st.indices, st.values, st.shape) for st in decoded_list]))\n",
    "\n",
    "      if expected_err_re is None:\n",
    "        outputs = sess.run(\n",
    "            decoded_unwrapped + [log_probability])\n",
    "\n",
    "        # Group outputs into (ix, vals, shape) tuples\n",
    "        output_sparse_tensors = list(grouper(outputs[:-1], 3))\n",
    "\n",
    "        output_log_probability = outputs[-1]\n",
    "\n",
    "        # Check the number of decoded outputs (top_paths) match\n",
    "        self.assertEqual(len(output_sparse_tensors), len(decode_truth))\n",
    "\n",
    "        # For each SparseTensor tuple, compare (ix, vals, shape)\n",
    "        for out_st, truth_st, tf_st in zip(\n",
    "            output_sparse_tensors, decode_truth, decoded_list):\n",
    "          self.assertAllEqual(out_st[0], truth_st[0])  # ix\n",
    "          self.assertAllEqual(out_st[1], truth_st[1])  # vals\n",
    "          self.assertAllEqual(out_st[2], truth_st[2])  # shape\n",
    "          # Compare the shapes of the components with the truth. The\n",
    "          # `None` elements are not known statically.\n",
    "          self.assertEqual([None, truth_st[0].shape[1]],\n",
    "                           tf_st.indices.get_shape().as_list())\n",
    "          self.assertEqual([None], tf_st.values.get_shape().as_list())\n",
    "          self.assertShapeEqual(truth_st[2], tf_st.shape)\n",
    "\n",
    "        # Make sure decoded probabilities match\n",
    "        self.assertAllClose(output_log_probability, log_prob_truth, atol=1e-6)\n",
    "      else:\n",
    "        with self.assertRaisesOpError(expected_err_re):\n",
    "          sess.run(decoded_unwrapped + [log_probability])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/neo/MS/TA/TCS_TL/env/lib/python3.6/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in log\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/home/neo/MS/TA/TCS_TL/env/lib/python3.6/site-packages/ipykernel_launcher.py:24: RuntimeWarning: divide by zero encountered in log\n"
     ]
    }
   ],
   "source": [
    "max_time_steps = 6\n",
    "seq_len_0 = 4\n",
    "input_prob_matrix_0 = np.asarray(\n",
    "    [[1.0, 0.0, 0.0, 0.0],  # t=0\n",
    "     [0.0, 0.0, 0.4, 0.6],  # t=1\n",
    "     [0.0, 0.0, 0.4, 0.6],  # t=2\n",
    "     [0.0, 0.9, 0.1, 0.0],  # t=3\n",
    "     [0.0, 0.0, 0.0, 0.0],  # t=4 (ignored)\n",
    "     [0.0, 0.0, 0.0, 0.0]],  # t=5 (ignored)\n",
    "    dtype=np.float32)\n",
    "input_log_prob_matrix_0 = np.log(input_prob_matrix_0)\n",
    "\n",
    "seq_len_1 = 5\n",
    "# dimensions are time x depth\n",
    "\n",
    "input_prob_matrix_1 = np.asarray(\n",
    "    [[0.1, 0.9, 0.0, 0.0],  # t=0\n",
    "     [0.0, 0.9, 0.1, 0.0],  # t=1\n",
    "     [0.0, 0.0, 0.1, 0.9],  # t=2\n",
    "     [0.0, 0.9, 0.1, 0.1],  # t=3\n",
    "     [0.9, 0.1, 0.0, 0.0],  # t=4\n",
    "     [0.0, 0.0, 0.0, 0.0]],  # t=5 (ignored)\n",
    "    dtype=np.float32)\n",
    "input_log_prob_matrix_1 = np.log(input_prob_matrix_1)\n",
    "\n",
    "# len max_time_steps array of batch_size x depth matrices\n",
    "inputs = [np.vstack([input_log_prob_matrix_0[t, :],\n",
    "                     input_log_prob_matrix_1[t, :]])\n",
    "          for t in range(max_time_steps)]\n",
    "\n",
    "# batch_size length vector of sequence_lengths\n",
    "seq_lens = np.array([seq_len_0, seq_len_1], dtype=np.int32)\n",
    "\n",
    "# batch_size length vector of negative log probabilities\n",
    "log_prob_truth = np.array([\n",
    "    np.sum(-np.log([1.0, 0.6, 0.6, 0.9])),\n",
    "    np.sum(-np.log([0.9, 0.9, 0.9, 0.9, 0.9]))\n",
    "], np.float32)[:, np.newaxis]\n",
    "\n",
    "# decode_truth: one SparseTensor (ix, vals, shape)\n",
    "decode_truth = [\n",
    "    (np.array([[0, 0],  # batch 0, 2 outputs\n",
    "               [0, 1],\n",
    "               [1, 0],  # batch 1, 3 outputs\n",
    "               [1, 1],\n",
    "               [1, 2]], dtype=np.int64),\n",
    "     np.array([0, 1,      # batch 0\n",
    "               1, 1, 0],  # batch 1\n",
    "              dtype=np.int64),\n",
    "     # shape is batch x max_decoded_length\n",
    "     np.array([2, 3], dtype=np.int64)),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparseTensor(indices=tf.Tensor(\n",
      "[[0 0]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [1 2]], shape=(5, 2), dtype=int64), values=tf.Tensor([0 1 1 1 0], shape=(5,), dtype=int64), dense_shape=tf.Tensor([2 3], shape=(2,), dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "print(tf.nn.ctc_greedy_decoder(inputs=inputs, sequence_length=seq_lens)[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth = 6\n",
    "\n",
    "seq_len_0 = 5\n",
    "input_prob_matrix_0 = np.asarray(\n",
    "    [[0.30999, 0.309938, 0.0679938, 0.0673362, 0.0708352, 0.173908],\n",
    "     [0.215136, 0.439699, 0.0370931, 0.0393967, 0.0381581, 0.230517],\n",
    "     [0.199959, 0.489485, 0.0233221, 0.0251417, 0.0233289, 0.238763],\n",
    "     [0.279611, 0.452966, 0.0204795, 0.0209126, 0.0194803, 0.20655],\n",
    "     [0.51286, 0.288951, 0.0243026, 0.0220788, 0.0219297, 0.129878],\n",
    "     # Random entry added in at time=5\n",
    "     [0.155251, 0.164444, 0.173517, 0.176138, 0.169979, 0.160671]],\n",
    "    dtype=np.float32)\n",
    "# Add arbitrary offset - this is fine\n",
    "input_log_prob_matrix_0 = np.log(input_prob_matrix_0) + 2.0\n",
    "\n",
    "# len max_time_steps array of batch_size x depth matrices\n",
    "inputs = ([input_log_prob_matrix_0[t, :][np.newaxis, :]\n",
    "           for t in range(seq_len_0)]  # Pad to max_time_steps = 8\n",
    "          + 2 * [np.zeros((1, depth), dtype=np.float32)])\n",
    "\n",
    "# batch_size length vector of sequence_lengths\n",
    "seq_lens = np.array([seq_len_0], dtype=np.int32)\n",
    "\n",
    "# batch_size length vector of negative log probabilities\n",
    "log_prob_truth = np.array([\n",
    "    0.584855,  # output beam 0\n",
    "    0.389139  # output beam 1\n",
    "], np.float32)[np.newaxis, :]\n",
    "\n",
    "# decode_truth: two SparseTensors, (ix, values, shape)\n",
    "decode_truth = [\n",
    "    # beam 0, batch 0, two outputs decoded\n",
    "    (np.array([[0, 0], [0, 1]], dtype=np.int64),\n",
    "     np.array([1, 0], dtype=np.int64),\n",
    "     np.array([1, 2], dtype=np.int64)),\n",
    "    # beam 1, batch 0, three outputs decoded\n",
    "    (np.array([[0, 0], [0, 1], [0, 2]], dtype=np.int64),\n",
    "     np.array([0, 1, 0], dtype=np.int64),\n",
    "     np.array([1, 3], dtype=np.int64)),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beam 0 output: SparseTensor(indices=tf.Tensor(\n",
      "[[0 0]\n",
      " [0 1]], shape=(2, 2), dtype=int64), values=tf.Tensor([1 0], shape=(2,), dtype=int64), dense_shape=tf.Tensor([1 2], shape=(2,), dtype=int64))\n",
      "Beam 1 output: SparseTensor(indices=tf.Tensor(\n",
      "[[0 0]\n",
      " [0 1]\n",
      " [0 2]], shape=(3, 2), dtype=int64), values=tf.Tensor([0 1 0], shape=(3,), dtype=int64), dense_shape=tf.Tensor([1 3], shape=(2,), dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "beam_results = tf.nn.ctc_beam_search_decoder(inputs=inputs, sequence_length=seq_lens, beam_width=2,top_paths=2)[0]\n",
    "for i,res in enumerate(beam_results):\n",
    "    print(\"Beam {0} output: {1}\".format(str(i), res))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
